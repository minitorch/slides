
.. raw:: html

   <link rel="stylesheet" href="_static/revealjs/css/theme/white.css">
   <link rel="stylesheet" href="_static/default.css">


Machine Learning Engineering
=============================================

Lecture 22
------------

   Convolution + Pooling


Module 4
---------

  `GitHub <https://classroom.github.com/classrooms/68973473-mle/assignments/minitorch-4>`_


Lecture
=========

Outline
---------

.. revealjs_fragments::

   * Review: Convolution
   * 2D+ Convolution
   * Pooling


Intuition
----------

.. revealjs_fragments::

   * Same neural network as before
   * Brute force, try running it everywhere
   * Hope it finds useful features at some locations


Convolution Forward
--------------------

.. image:: figs/Conv/conv1d.png
           :align: center

Computation
-----------

Output Values ::

  output[0] = weight[0] * input[0] + weight[1] * input[1]  + weight[2] * input[2]
  output[1] = weight[0] * input[1] + weight[1] * input[2]  + weight[2] * input[3]
  output[2] = weight[0] * input[2] + weight[1] * input[3]  + weight[2] * input[4]

Alternative View
-----------------

.. image:: figs/Conv/convvec.png
           :align: center


Alternative View
-----------------

Unroll and Zip ::

  input = minitorch.tensor([1, 2, 3, 4, 5, 6])
  input = unroll(input, K)
  print(input)

  [[1, 2, 3],
   [2, 3, 4],
   [3, 4, 5],
   [4, 5, 6],
   [5, 6, 0],
   [6, 0, 0],
   ]


Our Convention
---------------

* Input and Output same width
* A bit non-standard, but easier to code

Conv Back - Input
------------------

Reverse the convolutional anchor

.. image:: figs/Conv/conv1dback.png
           :align: center

Channels
------------

* Each position may have multiple values
* These may be meaningful - i.e. color channels
* These may be learned - i.e. hidden states


Key Points
----------

* Convolution is a Linear applied to all channels in position
* If weight is length K and there are 10 channels, the input to the linear
  is 10 * K.
* Output channels are just like the output of the Linear.



Graphical Representation
-------------------------

.. image:: figs/Conv/channels.png
           :align: center
           :width: 400px


Lecture Quiz
-------------

  `Quiz <https://canvas.cornell.edu/courses/20583/assignments/177168>`_


Two Dimensional Convolution
----------------------------

* Instead of line, now use box
* Box is anchored at the top-left
* Zip-reduce is over full box!


Convolution
-----------

.. image:: figs/Conv/conv.png
           :align: center

Conventions
-------------

Sizes ::

 # Input image - batch x in_channel x height x width
 # Weight - out_channel x in_channel x kernel_height x kernel_width
 # Output image - batch x out_channel x height x width

Alternative View
----------------



One step -> mat mul


Code ::


  output[b, oc, h, w] = sum([weight[oc, ic, kh, kw] * input[b, ic, h + kh, w + kw]
                             for ic, kh, kw in ...])
  # Input image - batch x (in_channel * height * width)
  # Weight - (in_channel * kernel_height * kernel_width) x out_channel


Backward
---------

.. image:: figs/Conv/backward.png
           :align: center

Backward
---------

Same idea as 1D

* Reverse weight (bottom-top, left-right)
* Anchor bottom-right
* Compute convolution

Channels
--------

Nothing different from 1D version

.. image:: figs/Conv/conv2.png
           :align: center
           :width: 500px

Implementation
--------------

.. revealjs_fragments::

   * All about understanding sizes.
   * Should be similar to matmul, start with output
   * If outside boundaries, use 0


Advice
-------

* Implement 1D first it is easier
* Compute a couple manually yourself.
* All about indexing

Where are we?
---------------

https://poloclub.github.io/cnn-explainer/


3D Convolution?
----------------

* Yeah!
* Several neat versions

3D Convolution Voxels
---------------------

.. image:: 3dconv.png
   :width: 700px

3D Convolution Chemistry
-------------------------

.. image:: chem.gif
   :width: 700px

3D Convolution Video
-------------------------

.. image:: video.jpeg
   :width: 700px

Graph Convolution
-------------------------

.. image:: graph.png
   :width: 700px

Pooling
=======

Challenge
---------

* How do we look at bigger areas with convolutions?


Issues
---------

* Number of parameters scale with weight size
* "Bigger" patterns require more ways to split data.

Goal
----

* Early layers: Capture basic shapes
* Middle layers: How these connect
* Later layers: Full objects


Example
--------

.. image:: vis.png


Pooling
----------

* Adjusts the scale at each layer
* Conv stays the same size, image "zooms" out


Pooling
----------

* Adjusts the scale at each layer
* Conv stays the same size, image "zooms" out


Standard Reduction
-------------------

.. image:: figs/Conv/pool1.png
           :align: center
           :width: 500px

"Pooling"
-----------

Reduction applied to each region:

.. image:: figs/Conv/pool2.png
           :align: center
           :width: 500px

Simple Implementation
----------------------

* Ensure that it is contiguous
* Use View to "fold" the tensor

.. image:: figs/Conv/pool3.png
           :align: center
           :width: 500px


Simple Implementation
----------------------

* Reduce along created fold


.. image:: figs/Conv/pool4.png
           :align: center
           :width: 500px

2D Pooling
-----------

.. image:: figs/Conv/pool2d.png
           :align: center
           :width: 500px


Fast Implementations?
---------------------

* If your reduce is on CUDA, can exploit small groups
* I.e. Prefix sum for each group on one block.


Q&A
-----
